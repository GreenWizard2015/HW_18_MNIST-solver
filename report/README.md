# Отчёт

Для тестирования различных вариантов нейронных сетей я решил использовать следующие условия:

- Модели получают на вход нормализированные данные в формате (28, 28). Целевые метки кодируются в one-hot encoded вектора.
- Каждая модель обучается максимум 100 эпох.
- Если модель не улучшает свой val_loss более 10 эпох, то обучение прерывается.
- Сохраняется модель с наименьшим val_loss и затем эта версия модели используется при тестировании.
- Модели получают те же самые наборы данных для валидации, чтоб полученные метрики были соизмеримы.

## Базовые модели.

Модели описаны в файле [baseline_models.py](../baseline_models.py).

Сравнение итоговой точности 4 базовых моделей:

![](baseline_accuracy.png)

Модель V4 даёт наибольшую итоговую точность (97.67%) и достигла этого уже на 9 эпохе. Остальные модели продолжали постепенно улучшаться на протяжение 100 эпох, но не достигли той же точности.

Матрицы ошибок моделей (исключая верные ответы и отсутствие ошибок):

![](baseline_confusion_matrix.png)

Как видно, общая плотность ошибок постепенно снижается, но все модели имеют тенденцию путать "4" и "9".